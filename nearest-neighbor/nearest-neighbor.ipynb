{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor \n",
    "# Lorenzo Speri and Carlo Tombolini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total asymptotic error is:\n",
    "\\begin{align}\n",
    "    P_{\\infty}(error) &=\n",
    "       = \\int _{-\\infty}^{+\\infty} p_{\\infty}(error | X) p(X)\\,dX\\\\\n",
    "\\end{align}\n",
    "<br>\n",
    "In the toy example $p(X)=1$ and $P_{\\infty}(error|X)=1-(1-x)^2-x^2$.\n",
    "<br>\n",
    "Inserting these values on the expression and taking the values of the integral between 0 and 1, we obtain:\n",
    "$$P_{\\infty}(error)=\\int _{0}^{1}(1-(1-x)^2-x^2)1\\cdot dX=\\int _{0}^{1}2(x-x^2)dX=[\\, x^2-\\frac{2x^2}{3} \\,]_{0}^{1}=1-\\frac{2}{3}=\\frac{1}{3}$$ \n",
    "\n",
    "This means that even if we collect an infinite amount of training data, the asymptotic result gives an error rate of 33%,  that is a slight improvement compared to the 35% obtained with a training set of size 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "data = digits[\"data\"]\n",
    "images = digits[\"images\"]\n",
    "target = digits[\"target\"]\n",
    "target_names = digits[\"target_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "from sklearn import model_selection\n",
    "X_all = data\n",
    "y_all = target\n",
    "\n",
    "X_train , X_test , y_train , y_test =\\\n",
    "model_selection.train_test_split(digits.data, digits.target,\\\n",
    "                  test_size = 0.4, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the data is:\n",
      "(1797, 64)\n",
      "The size of the images is:\n",
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "# the size of the images is 8x8 pixels \n",
    "print(\"The size of the data is:\")\n",
    "print(np.shape(data))\n",
    "print(\"The size of the images is:\")\n",
    "print(np.shape(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA4kROJDYvwFBuZfzuATFqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = images[3,:,:]\n",
    "\n",
    "print(target_names[3])\n",
    "assert 2 == len(img.shape)\n",
    "plt.figure()\n",
    "plt.gray()\n",
    "plt.imshow(img, interpolation=\"nearest\") # also try interpolation=\"bicubic\" \n",
    "plt.show()\n",
    "# visualize three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the matrix is:\n",
      "(1078, 719)\n",
      "The shape of the matrix is:\n",
      "(1078, 719)\n",
      "The shape of the matrix is:\n",
      "(1078, 719)\n",
      "The shape of the matrix is:\n",
      "(1078, 719)\n",
      "The shape of the matrix is:\n",
      "(1078, 719)\n",
      "7.26 s ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5 -r 1\n",
    "# distance\n",
    "import time\n",
    "\n",
    "def dist_loop(training,test):\n",
    "    d = np.zeros((len(training),len(test)))\n",
    "    for n in range(len(training)):\n",
    "        for m in range(len(test)):\n",
    "            d[n,m] = np.sqrt(np.sum(np.square(training[n,:]-test[m,:])))\n",
    "    return d\n",
    "\n",
    "dist_matrix = dist_loop(X_train, X_test)\n",
    "print(\"The shape of the matrix is:\")\n",
    "print(np.shape(dist_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_loop(train,test):\n",
    "    return np.sqrt(np.sum(np.square([i-test for i in train]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the matrix is:\n",
      "(1078, 719)\n",
      "The shape of the matrix is:\n",
      "(1078, 719)\n",
      "The shape of the matrix is:\n",
      "(1078, 719)\n",
      "The shape of the matrix is:\n",
      "(1078, 719)\n",
      "The shape of the matrix is:\n",
      "(1078, 719)\n",
      "1.35 s ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5 -r 1\n",
    "# distance vectorized\n",
    "def dist_loop(train,test):\n",
    "    return np.sqrt(np.sum(np.square([i-test for i in train]),2))\n",
    "\n",
    "dist_matrix_v = dist_loop(X_train, X_test)\n",
    "print(\"The shape of the matrix is:\")\n",
    "print(np.shape(dist_matrix_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapes of the two matrixes are $NxM$ and the the function that has been vectorized is more than 5 times faster than the other one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filtering data\n",
    "X_train_3 = X_train[np.where(y_train ==3)]\n",
    "X_test_3 = X_test[np.where(y_test ==3)]\n",
    "X_train_9 = X_train[np.where(y_train ==9)]\n",
    "X_test_9 = X_test[np.where(y_test ==9)]\n",
    "y_train_3_9 = np.concatenate((y_train[np.where(y_train ==3)],y_train[np.where(y_train ==9)]))\n",
    "y_test_3_9 = np.concatenate((y_test[np.where(y_test ==3)],y_test[np.where(y_test ==9)]))\n",
    "X_train_3_9 = np.concatenate((X_train_3, X_train_9))\n",
    "X_test_3_9 = np.concatenate((X_test_3, X_test_9))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different number of neighbors considered:\n",
      "[1, 3, 5, 9, 17, 33]\n",
      "Error per each value of k considered:\n",
      "[ 0.01388889  0.00694444  0.00694444  0.00694444  0.00694444  0.02083333]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the distance between train and test\n",
    "dist_3_9 = dist_loop(X_train_3_9,X_test_3_9)\n",
    "\n",
    "#Definition of k vector\n",
    "k = [1, 3, 5, 9, 17, 33]\n",
    "\n",
    "#Definition of error vector\n",
    "error = np.zeros(len(k))\n",
    "print(\"Different number of neighbors considered:\")\n",
    "print(k)\n",
    "for i in range(len(k)):\n",
    "    n_errors = 0\n",
    "    for j in range(len(X_test_3_9)):\n",
    "        first_row = dist_3_9[:,j]\n",
    "        idx = np.argpartition(first_row, k[i])\n",
    "        if mode(y_train_3_9[idx[:k[i]]])!= y_test_3_9[j]: n_errors += 1\n",
    "\n",
    "    error[i] = (n_errors/len(X_test_3_9))\n",
    "print(\"Error per each value of k considered:\")\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0208333333333\n"
     ]
    }
   ],
   "source": [
    "# k-nearest neighborfunction\n",
    "def k_NN(x_train, y_train, x_test, k):\n",
    "    # indeces of the closest instances to the test set\n",
    "    index = np.argsort(dist_loop(x_train,x_test), axis=0)[:k,:]\n",
    "    # print(np.shape(index))\n",
    "    # we take the mode of the k nearest values\n",
    "    prediction = stats.mode(y_train[index])[0][0]\n",
    "    return prediction\n",
    "    \n",
    "print(sum(k_NN(X_train_3_9, y_train_3_9, X_test_3_9,33)!=y_test_3_9)/len(y_test_3_9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for k=33 is the same, using both the function and the code without function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of our k-NN is 0.019 ± 0.008  and of sklearn algo is 0.019 ± 0.008 for L =2\n",
      "Error rate of our k-NN is 0.014 ± 0.022  and of sklearn algo is 0.017 ± 0.020 for L =5\n",
      "Error rate of our k-NN is 0.017 ± 0.022  and of sklearn algo is 0.014 ± 0.019 for L =10\n"
     ]
    }
   ],
   "source": [
    "X_3_9_joint = np.concatenate((X_train_3_9, X_test_3_9), axis=0)\n",
    "y_3_9_joint = np.concatenate((y_train_3_9, y_test_3_9), axis=0)\n",
    "\n",
    "def split_folds(data, target, L):\n",
    "    target_vert = np.vstack(target)\n",
    "    data_permuted = np.random.permutation(np.hstack((data, target_vert)))\n",
    "    X_folds = np.array_split(data_permuted[:,:64],L, axis = 0)\n",
    "    Y_folds = np.array_split(data_permuted[:,64],L, axis = 0)\n",
    "\n",
    "    return X_folds, Y_folds\n",
    "\n",
    "def error_function(y, f):   return sum((y!=f))/len(y)\n",
    "\n",
    "# function for the cross validation\n",
    "# k-nearest neighbor and sklearn\n",
    "def cross_validation(data, target, L, k):\n",
    "    # I randomly split the given data and labels into L folds\n",
    "    X,Y = split_folds(data, target, L)\n",
    "\n",
    "    # intilize error vectors\n",
    "    our_error = np.zeros(L)\n",
    "    sk_error = np.zeros(L)\n",
    "    \n",
    "    # I need to change the test set among the different folds\n",
    "    for j in range(L):\n",
    "        # training data\n",
    "        x_train = np.vstack(X[:j] + X[j+1:])\n",
    "        y_train = np.hstack(Y[:j] + Y[j+1:])\n",
    "        # test data\n",
    "        x_test = X[j]\n",
    "        y_test = Y[j]\n",
    "        \n",
    "        # our k_NN classifier  \n",
    "        our_prediction = k_NN(x_train, y_train, x_test,k)\n",
    "        \n",
    "        # sklearn neighbor classifier\n",
    "        sk=sklearn.neighbors.KNeighborsClassifier(k)\n",
    "        # train\n",
    "        sk.fit(x_train,y_train)\n",
    "        # classify\n",
    "        sk_prediction = sk.predict(x_test)\n",
    "        \n",
    "        # error evaluation of the two algorithms\n",
    "        our_error[j] = error_function(our_prediction,y_test)\n",
    "        sk_error[j] = error_function(sk_prediction,y_test)\n",
    "        \n",
    "    # statistics\n",
    "    our_avg_std = np.array([np.mean(our_error), np.std(our_error)])\n",
    "    sk_avg_std = np.array([np.mean(sk_error), np.std(sk_error)])\n",
    "        \n",
    "    return our_avg_std, sk_avg_std\n",
    "k=3\n",
    "\n",
    "for L in [2, 5, 10]:\n",
    "    our_result, sk_result =cross_validation(X_3_9_joint, y_3_9_joint, L, k)\n",
    "    print('Error rate of our k-NN is %1.3f ± %1.3f  and of sklearn algo is %1.3f ± %1.3f for L =%d'\n",
    "          %(our_result[0],our_result[1],sk_result[0],sk_result[1],L))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
